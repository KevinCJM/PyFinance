# -*- coding: utf-8 -*-
"""
A01_preprocess.py

ä¸€ä¸ªâ€œä¸“é—¨ç”¨äºæ–°é—»é¢„å¤„ç†â€çš„ç‹¬ç«‹è„šæœ¬ï¼š
- ä»…åšæ–‡æœ¬è§„èŒƒåŒ–ä¸æ¸…æ´—ï¼ˆä¸åšâ€œç›¸åŒæ–°é—»â€è¯†åˆ«ï¼‰ã€‚
- é¢å‘ä¸­æ–‡æ–°é—»ï¼Œä½¿ç”¨å‘é‡åŒ– pandas å­—ç¬¦ä¸²æ“ä½œä¸é¢„ç¼–è¯‘æ­£åˆ™ï¼Œå°½é‡é¿å…ä½æ•ˆå¾ªç¯ä¸é“¾å¼èµ‹å€¼è­¦å‘Šã€‚
- è¾“å‡ºè§„èŒƒåŒ–åˆ—ï¼štitle_norm, text_norm, doc_normï¼›å¹¶å‰”é™¤ç©ºæ–‡æœ¬è¡Œã€‚

ç”¨æ³•ç¤ºä¾‹ï¼š
    python A01_preprocess.py \
        --input test_news.parquet \
        --out-parquet test_news_clean.parquet \
        --out-excel test_news_clean.xlsx

å¯é€‰å¼€å…³ï¼š
    --drop-dup-title    æ¸…æ´—åæŒ‰ title_norm å»é‡ï¼ˆä»…é¢„å¤„ç†é˜¶æ®µçš„â€œæ˜¾å¼é‡å¤â€ï¼‰
    --drop-dup-text     æ¸…æ´—åæŒ‰ text_norm å»é‡
    --keep-original     è¾“å‡ºæ—¶æºå¸¦åŸå§‹ title/text åˆ—ï¼ˆé»˜è®¤ä¹Ÿä¼šä¿ç•™ï¼‰

æ³¨æ„ï¼š
- è¿™é‡Œä¸åšâ€œç›¸åŒæ–°é—»/ç›¸ä¼¼æ–°é—»â€çš„èšç±»æˆ–é˜ˆå€¼åˆ¤æ–­ï¼›é‚£éƒ¨åˆ†åœ¨ä¸‹ä¸€æ­¥å•ç‹¬è„šæœ¬å®ç°ã€‚
- ä¾èµ–ï¼špandas, numpyï¼ˆä¸ reï¼‰ã€‚
"""

import os
import sys
import re
import argparse
from typing import Iterable, Optional, Tuple, Dict

import numpy as np
import pandas as pd

# ---------- 1) é¢„ç¼–è¯‘æ­£åˆ™ä¸æ›¿æ¢è¡¨ ----------

# ç»Ÿä¸€ç©ºç™½
RE_SPACES = re.compile(r'\s+')

# HTML æ®‹ç•™
RE_HTML_ENT = re.compile(r'&lt;/?div&gt;|&nbsp;')

# $ åé¢ä¸æ˜¯æ•°å­—çš„ $
RE_DOLLAR_NONNUM = re.compile(r'\$(?!\d)')

# å¼€å¤´åƒ â€œITä¹‹å®¶6æœˆ3æ—¥æ¶ˆæ¯,â€ çš„å¤´
RE_IT_HOUSE = re.compile(r'^ITä¹‹å®¶\d{1,2}æœˆ\d{1,2}æ—¥æ¶ˆæ¯,')

# æ‹¬å·å†…å™ªå£°ï¼ˆæ¥æºã€è®°è€…ã€åŸæ ‡é¢˜ç­‰ï¼‰
RE_PAREN_NOISE = re.compile(
    r'\([^)]*(è®°è€…|æ¥æº|ç‰¹çº¦é€šè®¯å‘˜|é€šè®¯å‘˜|å›¾æº|æ–‡/|ä»¥ä¸‹ä¿¡æ¯ä»|ä»¥ä¸‹å†…å®¹ä»|åŸæ ‡é¢˜|æ‘˜è¦|ç§‘æŠ€æ¶ˆæ¯|æœ¬æŠ¥è®¯|Vè§‚è´¢æŠ¥|ç¼–è€…æŒ‰|è´¢åç¤¾è®¯|è´¢ç»æ—¥å†|ç¬¬ä¸€è´¢ç»|ç”µé³—è´¢ç»|æ³•æ²»å‘¨æœ«|ç§‘åˆ›æ¿æ—¥æŠ¥|é‡‘è¯ç ”|æ£€å¯Ÿæ—¥æŠ¥|åŸºé‡‘ç»ç†æŠ•èµ„ç¬”è®°|æ¯æ—¥ç»æµæ–°é—»)[^)]*\)'
)

# â€œæœ¬æŠ¥â€¦è®°è€…â€¦æŠ¥é“â€æ¨¡æ¿ï¼ˆå«å¯é€‰æ‹¬å·/åœ°ç‚¹ï¼‰
RE_BAODAO = re.compile(
    r'æœ¬æŠ¥(?:è®¯)?'  # å¯é€‰â€œæœ¬æŠ¥è®¯â€
    r'(?:ï¼ˆ[^ï¼‰]*ï¼‰|\([^)]*\)|ã€[^ã€‘]*ã€‘|\[[^\]]*\])?'  # å¯é€‰æ‹¬å·å—ï¼ˆå…¨/åŠè§’/æ–¹æ‹¬/ä¹¦åå·ï¼‰
    r'[^,.;:ï¼Œã€‚ï¼›ï¼š]*?è®°è€…'  # åˆ°â€œè®°è€…â€ä¸ºæ­¢ï¼ˆä¸è·¨å¥ï¼‰
    r'[^,.;:ï¼Œã€‚ï¼›ï¼š]*?æŠ¥é“'  # åˆ°â€œæŠ¥é“â€ä¸ºæ­¢ï¼ˆä¸è·¨å¥ï¼‰'
)

# å¤©çœ¼æŸ¥æ¨¡æ¿
RE_TYC = re.compile(
    r"(?:"
    r"æ ¹æ®å¤©çœ¼æŸ¥APPäº\d{1,2}æœˆ\d{1,2}æ—¥å…¬å¸ƒçš„ä¿¡æ¯æ•´ç†,?"  # æƒ…å½¢1
    r"|æ ¹æ®å¸‚åœºå…¬å¼€ä¿¡æ¯åŠ\d{1,2}æœˆ\d{1,2}æ—¥æŠ«éœ²çš„æœºæ„è°ƒç ”ä¿¡æ¯,?"  # æƒ…å½¢2
    r"|æ ¹æ®\d{1,2}æœˆ\d{1,2}æ—¥å¸‚åœºå…¬å¼€ä¿¡æ¯,ä¸Šå¸‚å…¬å¸å…¬å‘ŠåŠäº¤æ˜“æ‰€æŠ«éœ²æ•°æ®æ•´ç†,?"  # æƒ…å½¢3
    r"|æ ¼éš†æ±‡\d{1,2}æœˆ\d{1,2}æ—¥ä¸¨"  # æƒ…å½¢4
    r")"
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å·¥å•†ä¿¡æ¯å˜æ›´ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_BIZREG_DISCLOSURE = re.compile(
    r'(?P<year>19|20\d{2})å¹´(?P<month>\d{1,2})æœˆ(?P<day>\d{1,2})æ—¥'
    r'(?:æŠ«éœ²|å…¬å‘Š)[,:ï¼Œï¼š]\s*'
    r'(?P<company>.*?)'
    r'å·¥å•†ç™»è®°ä¿¡æ¯å‘ç”Ÿä»¥ä¸‹å˜åŠ¨[,:ï¼Œï¼š]\s*'
    r'(?P<details>.*)$',
    flags=re.UNICODE | re.DOTALL
)


def extract_bizreg_disclosure_rows(res: pd.DataFrame) -> pd.DataFrame:
    """
    ä»é¢„å¤„ç†ç»“æœ resï¼ˆéœ€å« text_normï¼‰ä¸­æŠ½å–ï¼š
    â€œYYYYå¹´MæœˆDæ—¥æŠ«éœ², XXXå…¬å¸ å·¥å•†ç™»è®°ä¿¡æ¯å‘ç”Ÿä»¥ä¸‹å˜åŠ¨: <details>â€ æ•´æ®µã€‚
    è¿”å›å«åŸæ–‡ä¸ç»“æ„åŒ–å­—æ®µï¼›æ— åŒ¹é…è¿”å›ç©ºè¡¨ã€‚
    """
    if 'text_norm' not in res.columns:
        return pd.DataFrame()

    t = res['text_norm']
    ext = t.str.extract(RE_BIZREG_DISCLOSURE)

    mask = ext['year'].notna()
    if not mask.any():
        return pd.DataFrame()

    ext = ext.loc[mask].reset_index(drop=True)

    # æ—¥æœŸ
    date = pd.to_datetime(
        ext['year'].astype(str) + '-' +
        ext['month'].astype(str).str.zfill(2) + '-' +
        ext['day'].astype(str).str.zfill(2),
        errors='coerce'
    )

    # ç»„è£…â€œåªè¦è¿™æ®µâ€çš„çº¯æ–‡æœ¬ï¼ˆå«æ—¥æœŸ+æŠ«éœ²+å…¬å¸+å˜åŠ¨ï¼‰
    extracted_text = (
            ext['year'].astype(str) + 'å¹´' +
            ext['month'].astype(str) + 'æœˆ' +
            ext['day'].astype(str) + 'æ—¥æŠ«éœ²,' +
            ext['company'].str.strip() +
            'å·¥å•†ç™»è®°ä¿¡æ¯å‘ç”Ÿä»¥ä¸‹å˜åŠ¨:' +
            ext['details'].str.strip()
    )

    # åŸæ–‡åˆ—ï¼ˆå®¡è®¡ç”¨ï¼Œè‹¥ä¸å­˜åœ¨ç›¸åº”åˆ—åˆ™è‡ªåŠ¨è·³è¿‡ï¼‰
    base_cols = [c for c in ['title', 'text', 'title_norm', 'text_norm', 'doc_norm'] if c in res.columns]
    base = res.loc[mask, base_cols].reset_index(drop=True)

    out = pd.DataFrame({
        'date': date,
        'company': ext['company'].str.strip(),
        'details': ext['details'].str.strip(),
        'extracted_text': extracted_text
    })

    return pd.concat([base, out], axis=1)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” é‡‘èç•Œå‡€å€¼å¿«è®¯æå– â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_JRJ_NAV = re.compile(
    r'^é‡‘èç•Œ'
    r'(?P<year>\d{4})å¹´(?P<month>\d{1,2})æœˆ(?P<day>\d{1,2})æ—¥æ¶ˆæ¯,'  # æ—¥æœŸ
    r'(?P<fund_name>[^()ï¼Œ,]+)\((?P<code>\d{6})\)'  # åŸºé‡‘å + 6ä½ä»£ç 
    r'æœ€æ–°å‡€å€¼(?P<nav>\d+(?:\.\d+)?)å…ƒ,'  # æœ€æ–°å‡€å€¼
    r'(?P<dir>å¢é•¿|ä¸Šæ¶¨|ä¸Šå‡|ä¸‹è·Œ|ä¸‹é™)'  # æ–¹å‘
    r'(?P<chg>-?\d+(?:\.\d+)?)%'  # ç™¾åˆ†æ¯”
    r'[ã€‚\.ï¼Œ,]?',  # æœ«å°¾å¯é€‰æ ‡ç‚¹
    flags=re.UNICODE
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” é‡‘èç•Œå‡€å€¼ç±»å¿«è®¯æ•°æ®æå– â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_JRJ_TAIL = re.compile(
    r'è¿‘1ä¸ªæœˆæ”¶ç›Šç‡(?P<ret_1m>-?\d+(?:\.\d+)?)%,åŒç±»æ’å(?P<rank_1m>\d+)\|(?P<base_1m>\d+);'
    r'è¿‘3ä¸ªæœˆæ”¶ç›Šç‡(?P<ret_3m>-?\d+(?:\.\d+)?)%,åŒç±»æ’å(?P<rank_3m>\d+)\|(?P<base_3m>\d+);'
    r'(?:ä»Šå¹´æ¥|å¹´å†…)æ”¶ç›Šç‡(?P<ret_ytd>-?\d+(?:\.\d+)?)%,åŒç±»æ’å(?P<rank_ytd>\d+)\|(?P<base_ytd>\d+)',
    flags=re.UNICODE
)

DIR_SIGN_MAP = {'å¢é•¿': 1, 'ä¸Šæ¶¨': 1, 'ä¸Šå‡': 1, 'ä¸‹è·Œ': -1, 'ä¸‹é™': -1}


def extract_jrj_nav_rows(res: pd.DataFrame) -> pd.DataFrame:
    """
    åœ¨é¢„å¤„ç†ç»“æœ res ä¸Šï¼ˆåŒ…å« text_normï¼‰å‘é‡åŒ–æŠ½å–â€œé‡‘èç•Œå‡€å€¼ç±»å¿«è®¯â€ã€‚
    è¿”å›å«è§£æå­—æ®µçš„ DataFrameï¼›è‹¥æ— åŒ¹é…ï¼Œè¿”å›ç©ºè¡¨ã€‚
    """
    if 'text_norm' not in res.columns:
        return pd.DataFrame()

    t = res['text_norm']
    head = t.str.extract(RE_JRJ_NAV)

    mask = head['year'].notna()
    if not mask.any():
        return pd.DataFrame()

    # åŸºç¡€åˆ—ï¼ˆä¿ç•™åŸæ–‡ä¾¿äºå®¡è®¡ï¼‰
    base = res.loc[mask, ['title', 'text', 'title_norm', 'text_norm', 'doc_norm']].reset_index(drop=True)

    # å¤´éƒ¨ç»“æ„åŒ–å­—æ®µ
    head = head.loc[mask].reset_index(drop=True)
    date_str = (
            head['year'].astype(str) + '-' +
            head['month'].astype(str).str.zfill(2) + '-' +
            head['day'].astype(str).str.zfill(2)
    )

    # å°¾æ®µç»“æ„åŒ–å­—æ®µï¼ˆå¯é€‰ï¼‰
    tail = t.loc[mask].str.extract(RE_JRJ_TAIL)

    out = pd.DataFrame({
        'date': pd.to_datetime(date_str, errors='coerce'),
        'fund_name': head['fund_name'],
        'fund_code': head['code'],
        'nav': pd.to_numeric(head['nav'], errors='coerce'),
        'direction': head['dir'],
        # è§„èŒƒåŒ–æ¶¨è·Œå¹…ï¼šæ–¹å‘ï¼ˆÂ±1ï¼‰* |æ•°å€¼|
        'chg_pct': pd.to_numeric(head['chg'], errors='coerce').abs() *
                   head['dir'].map(DIR_SIGN_MAP).astype('float64')
    })

    # è¿½åŠ å°¾æ®µå­—æ®µï¼ˆè‹¥ç¼ºå¤±åˆ™ä¸º NaNï¼‰
    for col in ['ret_1m', 'ret_3m', 'ret_ytd']:
        out[col] = pd.to_numeric(tail.get(col), errors='coerce')
    for col in ['rank_1m', 'base_1m', 'rank_3m', 'base_3m', 'rank_ytd', 'base_ytd']:
        out[col] = pd.to_numeric(tail.get(col), errors='coerce', downcast='integer')

    # åˆå¹¶å›åŸæ–‡ï¼Œä¾¿äºäººå·¥æ ¸å¯¹
    out = pd.concat([base, out], axis=1)
    return out


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” é‡ä»“è‚¡å¿«è®¯æå–ï¼ˆæœ€æ–°æŠ«éœ²æ•°æ®æ˜¾ç¤ºâ€¦åå¤§é‡ä»“è‚¡ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_TOP_HOLDINGS = re.compile(
    r'æœ€æ–°æŠ«éœ²æ•°æ®æ˜¾ç¤º,'  # èµ·å§‹é”šç‚¹ï¼ˆå…è®¸å‰é¢è¿˜æœ‰åˆ«çš„è¯ï¼Œextractä¼šsearchï¼‰
    r'æˆª(?:è‡³|æ­¢)'  # æˆªè‡³/æˆªæ­¢ å…¼å®¹
    r'(?P<year>\d{4})å¹´(?P<month>\d{1,2})æœˆ(?P<day>\d{1,2})æ—¥'
    r'(?:æ¶ˆæ¯)?,'  # å¯é€‰â€œæ¶ˆæ¯,â€
    r'(?P<company>[^,;ï¼Œï¼›]+?)'  # å…¬å¸åï¼ˆåˆ°â€œç°èº«/å‡ºç°åœ¨â€ä¹‹å‰ï¼‰
    r'(?:ç°èº«|å‡ºç°åœ¨)'  # ç°èº«/å‡ºç°åœ¨
    r'(?P<funds>\d+)åªåŸºé‡‘çš„(?:å‰)?åå¤§é‡ä»“è‚¡(?:ä¸­)?,'  # â€œå‰åå¤§â€å¯é€‰ï¼Œâ€œä¸­â€å¯é€‰
    r'è¾ƒä¸Šå­£åº¦(?:'  # åŒç¯æ¯”æè¿°
    r'(?P<dir>å¢åŠ |å‡å°‘)(?:äº†)?(?P<delta>\d+)åª'  # å¢åŠ /å‡å°‘ï¼ˆå¯å¸¦â€œäº†â€ï¼‰
    r'|æŒå¹³)'  # æˆ–â€œæŒå¹³â€
    r'[;,ï¼Œ]'  # åˆ†éš”ç¬¦
    r'åˆè®¡æŒæœ‰(?P<shares>\d+(?:\.\d+)?)(?P<shares_unit>[ä¸‡äº¿]?)è‚¡,'  # è‚¡æ•° + å•ä½
    r'(?:æŒè‚¡|æŒä»“)å¸‚å€¼(?P<mv>\d+(?:\.\d+)?)(?P<mv_unit>ä¸‡äº¿|ä¸‡|äº¿)å…ƒ'  # é‡‘é¢ + å•ä½ï¼ˆå«â€œä¸‡äº¿â€ï¼‰
    r'(?:|(?=,|ï¼Œ|ã€‚|\.))[,ï¼Œ]?'  # åé¢å¯èƒ½è¿˜æœ‰é€—å·
    r'ä¸ºå…¬å‹ŸåŸºé‡‘ç¬¬(?P<rank>\d+)å¤§é‡ä»“è‚¡'
    r'(?:\((?:æŒ‰)?[^)]*(?:å¸‚å€¼|æŒè‚¡å¸‚å€¼)[^)]*\))?',  # æ‹¬æ³¨é‡Œâ€œæ’åº/æ’å/æŒ‰â€¦å¸‚å€¼â€¦â€ ç­‰éƒ½æ”¾å®½
    flags=re.UNICODE
)

TOP_DIR_SIGN = {'å¢åŠ ': 1, 'å‡å°‘': -1}
UNIT_TO_NUM = {'': 1.0, 'ä¸‡': 1e4, 'äº¿': 1e8, 'ä¸‡äº¿': 1e12}  # é‡‘é¢/è‚¡æ•°ç»Ÿä¸€å€æ•°è¡¨


def extract_top_holdings_rows(res: pd.DataFrame) -> pd.DataFrame:
    """
    åœ¨é¢„å¤„ç†ç»“æœ resï¼ˆéœ€å« text_normï¼‰ä¸ŠæŠ½å–â€œæœ€æ–°æŠ«éœ²æ•°æ®æ˜¾ç¤ºâ€¦åå¤§/å‰åå¤§é‡ä»“è‚¡â€ç±»æ–°é—»ã€‚
    è¿”å›ç»“æ„åŒ–å­—æ®µï¼›æ— åŒ¹é…è¿”å›ç©ºè¡¨ã€‚
    """
    if 'text_norm' not in res.columns:
        return pd.DataFrame()

    ext = res['text_norm'].str.extract(RE_TOP_HOLDINGS)  # search è¯­ä¹‰
    mask = ext['year'].notna()
    if not mask.any():
        return pd.DataFrame()

    ext = ext.loc[mask].reset_index(drop=True)

    # æ—¥æœŸ
    date = pd.to_datetime(
        ext['year'].astype(str) + '-' +
        ext['month'].astype(str).str.zfill(2) + '-' +
        ext['day'].astype(str).str.zfill(2),
        errors='coerce'
    )

    # åŸºç¡€æ•°å€¼
    funds = pd.to_numeric(ext['funds'], errors='coerce').astype('Int64')

    # åŒç¯æ¯”å˜åŒ–ï¼šå¢åŠ /å‡å°‘ â†’ Â±deltaï¼›æŒå¹³ â†’ 0
    has_dir = ext['dir'].notna()
    qoq_change = pd.Series(pd.NA, index=ext.index, dtype='Int64')
    qoq_change.loc[has_dir] = (
            ext.loc[has_dir, 'dir'].map(TOP_DIR_SIGN).astype('float64') *
            pd.to_numeric(ext.loc[has_dir, 'delta'], errors='coerce')
    ).round().astype('Int64')
    qoq_change.loc[~has_dir] = 0  # â€œæŒå¹³â€åˆ†æ”¯

    # è‚¡æ•°ï¼šåŸå€¼Ã—å•ä½
    shares_val = pd.to_numeric(ext['shares'], errors='coerce')
    shares_mul = ext['shares_unit'].map(UNIT_TO_NUM).astype('float64')
    shares_abs = shares_val * shares_mul  # è‚¡

    # é‡‘é¢ï¼šåŸå€¼Ã—å•ä½ï¼ˆå…¼å®¹ ä¸‡äº¿/ä¸‡/äº¿ï¼‰
    mv_val = pd.to_numeric(ext['mv'], errors='coerce')
    mv_mul = ext['mv_unit'].map(UNIT_TO_NUM).astype('float64')
    mv_cny = mv_val * mv_mul  # å…ƒ

    rank = pd.to_numeric(ext['rank'], errors='coerce').astype('Int64')

    # åŸæ–‡åˆ—ï¼ˆä¾¿äºå®¡è®¡ï¼‰
    base_cols = [c for c in ['title', 'text', 'title_norm', 'text_norm', 'doc_norm'] if c in res.columns]
    base = res.loc[mask, base_cols].reset_index(drop=True)

    out = pd.DataFrame({
        'date': date,
        'company': ext['company'],
        'fund_count': funds,
        'qoq_change': qoq_change,  # è¾ƒä¸Šå­£åº¦å˜åŒ–ï¼š+/-Nï¼›æŒå¹³=0
        'shares': shares_abs,  # ç»å¯¹è‚¡æ•°ï¼ˆè‚¡ï¼‰
        'shares_value': shares_val,  # åŸå€¼
        'shares_unit': ext['shares_unit'],  # '', 'ä¸‡', 'äº¿'
        'market_value_cny': mv_cny,  # ç»å¯¹é‡‘é¢ï¼ˆå…ƒï¼‰
        'market_value_value': mv_val,  # åŸå€¼
        'market_value_unit': ext['mv_unit'],  # 'ä¸‡', 'äº¿', 'ä¸‡äº¿'
        'rank_by_mktvalue': rank
    })

    out = pd.concat([base, out], axis=1)
    return out


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” è¯åˆ¸ä¹‹æ˜Ÿç›˜ä¸­æ¶ˆæ¯æå–ï¼ˆå…¼å®¹â€œæ—¶é—´åœ¨å…¬å¸å‰/åâ€çš„ä¸¤ç§å†™æ³• â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_SZX_HEAD = re.compile(
    r'^è¯åˆ¸ä¹‹æ˜Ÿ(?P<month>\d{1,2})æœˆ(?P<day>\d{1,2})æ—¥ç›˜ä¸­æ¶ˆæ¯,'
    r'(?:'
    r'(?P<comp1>[^,(ï¼Œ]+)\((?P<code1>\d{6})\)(?P<h1>\d{1,2})ç‚¹(?P<m1>\d{1,2})åˆ†'  # å…¬å¸â†’æ—¶é—´
    r'|'
    r'(?P<h2>\d{1,2})ç‚¹(?P<m2>\d{1,2})åˆ†(?P<comp2>[^,(ï¼Œ]+)\((?P<code2>\d{6})\)'  # æ—¶é—´â†’å…¬å¸
    r')'
    r'(?P<event>[^ã€‚\.]*)[ã€‚\.]',
    flags=re.UNICODE
)

RE_SZX_PRICE = re.compile(
    r'(?:å½“å‰è‚¡ä»·ä¸º|ç›®å‰ä»·æ ¼)'
    r'(?P<price>\d+(?:\.\d+)?)(?:å…ƒ)?[,ï¼Œ]?\s*'
    r'(?:(?P<ud>æ¶¨|è·Œ|ä¸Šæ¶¨|ä¸‹è·Œ)\s*(?P<pct>\d+(?:\.\d+)?)%)?',
    flags=re.UNICODE
)

UD_SIGN = {'æ¶¨': 1, 'ä¸Šæ¶¨': 1, 'è·Œ': -1, 'ä¸‹è·Œ': -1}


def extract_szx_intraday_rows(res: pd.DataFrame) -> pd.DataFrame:
    """
    ä»é¢„å¤„ç†ç»“æœ resï¼ˆéœ€å« text_normï¼‰æŠ½å–â€œè¯åˆ¸ä¹‹æ˜Ÿxxæœˆxxæ—¥ç›˜ä¸­æ¶ˆæ¯â€ç±»å¿«è®¯ã€‚
    è¿”å›ç»“æ„åŒ–å­—æ®µï¼›æ— åŒ¹é…è¿”å›ç©ºè¡¨ã€‚
    """
    if 'text_norm' not in res.columns:
        return pd.DataFrame()

    t = res['text_norm']

    # å¤´éƒ¨è§£æï¼ˆå…¬å¸/ä»£ç /æ—¶é—´/äº‹ä»¶å¥ï¼‰
    head = t.str.extract(RE_SZX_HEAD)

    mask = head['month'].notna()
    if not mask.any():
        return pd.DataFrame()

    head = head.loc[mask].reset_index(drop=True)

    # ç»Ÿä¸€å…¬å¸ä¸ä»£ç ï¼ˆæ—¶é—´åœ¨å‰/åä¸¤ç§å†™æ³•åˆå¹¶ï¼‰
    comp = head['comp1'].fillna(head['comp2'])
    code = head['code1'].fillna(head['code2'])
    hh = head['h1'].fillna(head['h2'])
    mm = head['m1'].fillna(head['m2'])

    # è§£æä»·æ ¼ä¸æ¶¨è·Œå¹…ï¼ˆå‘é‡åŒ–ï¼‰
    price_ext = t.loc[mask].str.extract(RE_SZX_PRICE)
    price = pd.to_numeric(price_ext['price'], errors='coerce')
    pct = pd.to_numeric(price_ext['pct'], errors='coerce')
    sign = price_ext['ud'].map(UD_SIGN).astype('float64')
    chg_pct = pct.where(pct.notna(), pd.NA)
    # è‹¥å­˜åœ¨æ–¹å‘è¯ï¼Œåˆ™èµ‹äºˆç¬¦å·
    chg_pct = (chg_pct * sign).astype('Float64')

    # å®¡è®¡ä¿ç•™åŸæ–‡
    base_cols = [c for c in ['title', 'text', 'title_norm', 'text_norm', 'doc_norm'] if c in res.columns]
    base = res.loc[mask, base_cols].reset_index(drop=True)

    out = pd.DataFrame({
        'month': pd.to_numeric(head['month'], errors='coerce').astype('Int64'),
        'day': pd.to_numeric(head['day'], errors='coerce').astype('Int64'),
        'time_hhmm': hh.str.zfill(2) + ':' + mm.str.zfill(2),
        'company': comp,
        'code': code,
        'event': head['event'].str.strip(),  # ä¾‹ï¼šè‚¡ä»·åˆ›60æ—¥æ–°é«˜ / è§¦åŠæ¶¨åœæ¿ / è§¦åŠè·Œåœæ¿
        'price': price,  # å½“å‰/ç›®å‰ä»·æ ¼
        'chg_pct': chg_pct  # æ¶¨è·Œå¹…ï¼ˆå¸¦æ­£è´Ÿå·ï¼‰
    })

    out = pd.concat([base, out], axis=1)
    return out


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” æœºæ„è¯„çº§å¿«è®¯ï¼ˆè¡Œé¦–â€œæœºæ„:ç»´æŒ|ä¸Šè°ƒ|ä¸‹è°ƒ â€¦â€ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_RT_HEAD = re.compile(
    r'^(?P<inst>[^:ï¼š]+)[:ï¼š]'
    r'(?P<action>ç»´æŒ|ä¸Šè°ƒ|ä¸‹è°ƒ)'
    r'(?P<name>[^,ï¼Œ()\uFF08\uFF09]+?)'  # å…¬å¸/å›½å®¶/å®ä½“åï¼ˆå…è®¸è‹±æ–‡å­—æ¯/æ–œæ ç­‰ï¼Œç›´åˆ°é€—å·æˆ–æ‹¬å·ï¼‰
    r'(?:\((?P<ticker>[A-Z0-9][A-Z0-9.\-]{0,19})\))?'  # å¯é€‰è‚¡ç¥¨ä»£ç ï¼šå¦‚ TWLO.US / 600000.SH
    r'è¯„çº§?',  # â€œè¯„çº§â€å¯æœ‰å¯æ— 
    flags=re.UNICODE
)

# è¯„çº§å˜åŒ–ä¸¤ç§å†™æ³•ï¼šâ‘  ç”±Aè°ƒæ•´è‡³Bè¯„çº§ï¼›â‘¡ è¯„çº§è‡³/ä¸ºB
RE_RT_CHANGE = re.compile(r'ç”±(?P<rt_from>[^,ï¼Œã€‚\.]+?)è°ƒæ•´è‡³(?P<rt_to>[^,ï¼Œã€‚\.]+?)è¯„çº§', flags=re.UNICODE)
RE_RT_TOONLY = re.compile(r'è¯„çº§(?:è‡³|ä¸º)(?P<rt_to_only>[^,ï¼Œã€‚\.]+)', flags=re.UNICODE)

# ç›®æ ‡ä»·ä¸¤ç§å†™æ³•ï¼šâ‘  ç›®æ ‡ä»·ç”±Xè´§å¸è°ƒæ•´è‡³Yè´§å¸ï¼›â‘¡ ç›®æ ‡ä»·ä¸º/ç›®æ ‡ä»· Xè´§å¸
RE_RT_TP_CHANGE = re.compile(
    r'ç›®æ ‡ä»·(?:ä¸º)?ç”±(?P<tp_from>\d+(?:\.\d+)?)(?P<cur_from>[A-Za-z\u4e00-\u9fa5]+)'
    r'è°ƒæ•´è‡³(?P<tp_to>\d+(?:\.\d+)?)(?P<cur_to>[A-Za-z\u4e00-\u9fa5]+)',
    flags=re.UNICODE
)
RE_RT_TP_SINGLE = re.compile(
    r'ç›®æ ‡ä»·(?:ä¸º)?(?P<tp_single>\d+(?:\.\d+)?)(?P<cur_single>[A-Za-z\u4e00-\u9fa5]+)',
    flags=re.UNICODE
)

# å±•æœ›/å‰æ™¯
RE_RT_OUTLOOK = re.compile(r'(?:å‰æ™¯|è¯„çº§)?å±•æœ›(?P<outlook>[^,ï¼Œã€‚\.]+)', flags=re.UNICODE)

# åŠ¨ä½œç¬¦å·ï¼šä¸Šè°ƒ=+1ï¼Œä¸‹è°ƒ=-1ï¼Œç»´æŒ=0
RT_ACTION_SIGN = {'ä¸Šè°ƒ': 1, 'ä¸‹è°ƒ': -1, 'ç»´æŒ': 0}

# è´§å¸æ–‡æœ¬ â†’ ä»£ç 
CURRENCY_MAP = {
    'ç¾å…ƒ': 'USD', 'ç¾é‡‘': 'USD', 'æ¸¯å…ƒ': 'HKD', 'æ¸¯å¸': 'HKD', 'äººæ°‘å¸': 'CNY', 'å…ƒ': 'CNY',
    'æ¬§å…ƒ': 'EUR', 'è‹±é•‘': 'GBP', 'æ—¥å…ƒ': 'JPY', 'åŠ å…ƒ': 'CAD'
}


def extract_rating_change_rows(res: pd.DataFrame) -> pd.DataFrame:
    """
    åœ¨é¢„å¤„ç†ç»“æœ resï¼ˆéœ€å« text_normï¼‰ä¸ŠæŠ½å–â€œæœºæ„è¯„çº§å˜åŠ¨â€ç±»æ–°é—»ã€‚
    è¿”å›ç»“æ„åŒ–å­—æ®µï¼›æ— åŒ¹é…è¿”å›ç©ºè¡¨ã€‚
    """
    if 'text_norm' not in res.columns:
        return pd.DataFrame()

    t = res['text_norm']

    # 1) å¤´éƒ¨ï¼šæœºæ„ / åŠ¨ä½œ / åç§° / ä»£ç 
    head = t.str.extract(RE_RT_HEAD)
    mask = head['inst'].notna()
    if not mask.any():
        return pd.DataFrame()

    head = head.loc[mask].reset_index(drop=True)
    sub = t.loc[mask].reset_index(drop=True)  # ä¸ head å¯¹é½çš„æ­£æ–‡ç‰‡æ®µ

    # 2) è¯„çº§å˜åŒ–
    chg = sub.str.extract(RE_RT_CHANGE)
    to_only = sub.str.extract(RE_RT_TOONLY)

    rating_from = chg['rt_from']
    rating_to = chg['rt_to'].where(chg['rt_to'].notna(), to_only['rt_to_only'])

    # 3) ç›®æ ‡ä»·
    tp_chg = sub.str.extract(RE_RT_TP_CHANGE)
    tp_single = sub.str.extract(RE_RT_TP_SINGLE)

    # å˜åŒ–å¼
    tp_from = pd.to_numeric(tp_chg['tp_from'], errors='coerce')
    cur_from = tp_chg['cur_from'].map(CURRENCY_MAP).fillna(tp_chg['cur_from'])
    tp_to = pd.to_numeric(tp_chg['tp_to'], errors='coerce')
    cur_to = tp_chg['cur_to'].map(CURRENCY_MAP).fillna(tp_chg['cur_to'])

    # å•å€¼å¼ï¼ˆä»…å½“å˜åŒ–å¼ç¼ºå¤±æ—¶å¯ç”¨ï¼‰
    tp_one = pd.to_numeric(tp_single['tp_single'], errors='coerce')
    cur_one = tp_single['cur_single'].map(CURRENCY_MAP).fillna(tp_single['cur_single'])

    tp_from = tp_from.where(tp_from.notna(), pd.NA)
    cur_from = cur_from.where(tp_from.notna(), pd.NA)
    tp_to = tp_to.where(tp_to.notna(), pd.NA)
    cur_to = cur_to.where(tp_to.notna(), pd.NA)

    # 4) å±•æœ›/å‰æ™¯
    outk = sub.str.extract(RE_RT_OUTLOOK)['outlook']

    # 5) ç»“æ„åŒ–è¾“å‡º
    base_cols = [c for c in ['title', 'text', 'title_norm', 'text_norm', 'doc_norm'] if c in res.columns]
    base = res.loc[mask, base_cols].reset_index(drop=True)

    out = pd.DataFrame({
        'institution': head['inst'],
        'action': head['action'],
        'action_sign': head['action'].map(RT_ACTION_SIGN).astype('Int64'),
        'entity_name': head['name'].str.strip(),
        'ticker': head['ticker'],
        'rating_from': rating_from,
        'rating_to': rating_to,
        'tp_from': tp_from.astype('Float64'),
        'currency_from': cur_from,
        'tp_to': tp_to.astype('Float64'),
        'currency_to': cur_to,
        'tp_single': tp_one.astype('Float64'),
        'currency_single': cur_one,
        'outlook': outk
    })

    out = pd.concat([base, out], axis=1)
    return out


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å‹ç¼©è¿ç»­çš„å¥ç‚¹ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RE_MULTI_DOTS = re.compile(r'\.{2,}')

# å•å­—ç¬¦æ˜ å°„ï¼ˆtranslate æ›´å¿«ï¼‰ï¼›åŒ…å«åŠè§’åŒ–/ç»Ÿä¸€æ ‡ç‚¹/å»è£…é¥°ç¬¦
SINGLE_CHAR_MAP = {
    'ã€': ',', 'ï¼Œ': ',', 'ã€‚': '.', 'ï¼': '!', 'ï¼Ÿ': '?', 'ï¼›': ';', 'ï¼š': ':',
    'ï¼ˆ': '(', 'ï¼‰': ')', 'ã€': '(', 'ã€‘': ')', 'ã€Š': '(', 'ã€‹': ')',
    'â€œ': '"', 'â€': '"', 'â€˜': '"', 'â€™': '"', 'ã€': '"', 'ã€': '"',
    'ãƒ»': '-', 'ï½': '-', 'â€”': '-', 'â€¦': '.',  # å¤šä¸ªç‚¹åç»­ç»Ÿä¸€å‹ç¼©
    'Â·': '', 'â—': '', 'â– ': '', 'â–²': '', 'â–¼': '', 'â–': '', 'â–': '',
    'â–Œ': '', 'â–': '', 'â–¡': '', 'â–³': '', 'â–½': '', 'â–º': '', 'â–¶': '',
    'â—€': '', 'â—†': '', 'â—‡': '', 'â˜…': '', 'â˜†': '', 'â€»': '', 'â—': '',
    'ã€“': '', '#': '', '*': '', 'ï¼Š': '', 'Â§': '', 'Â©': '', 'Â®': '',
    '[': '(', ']': ')', '{': '(', '}': ')', '<': '(', '>': ')'
}
TRANS_TABLE = str.maketrans(SINGLE_CHAR_MAP)

# ç«™ç‚¹/å£å·ç±»çŸ­è¯­ç»Ÿä¸€ï¼ˆå¯æŒ‰éœ€è¡¥å……ï¼‰
PHRASE_MAP = {
    'é˜¿é‡Œå·´å·´é›†å›¢': 'é˜¿é‡Œ', 'é˜¿é‡Œå·´å·´': 'é˜¿é‡Œ',
    'åŒ—äº¬å•†æŠ¥è®¯': '', 'åŒ—äº¬å•†æŠ¥': '',
    'cninfo.com.cn': 'cninfo', 'cninfo.com': 'cninfo',
    'DoNews.com': 'DoNews', 'DoNews.cn': 'DoNews',
    'Windæ•°æ®æ˜¾ç¤º,': '', 'Windèµ„è®¯,': '', 'Windèµ„è®¯': '',
    'æ±‡é€šè´¢ç»APPè®¯--': '', 'è§‚ç‚¹ç½‘è®¯:': '',
    'æ ¹æ®å¤©çœ¼æŸ¥APPä¿¡æ¯æ•´ç†,': '', 'æ ¹æ®å¤©çœ¼æŸ¥-å¸æ³•æ¡ˆä»¶æ•°æ®æ•´ç†,': '', 'æ ¹æ®å¤©çœ¼æŸ¥-å¤©çœ¼é£é™©æ•°æ®æ•´ç†,': '',
    'YYç‚¹è¯„:': '', 'YYç‚¹è¯„': '', 'æ ¹æ®å¸‚åœºå…¬å¼€ä¿¡æ¯æ•´ç†,': '',
    'æ ¹æ®ä¼æŸ¥æŸ¥æ•°æ®æ˜¾ç¤º,è¿‘æ—¥å…¬å¸ƒäº†': '', 'æ ¹æ®ä¼æŸ¥æŸ¥æ•°æ®æ˜¾ç¤º,': '',
    'æ ¹æ®12315æ¶ˆè´¹è€…æŠ•è¯‰ä¿¡æ¯å…¬ç¤ºå¹³å°æ•°æ®,': '',
    'ğŸ‘‡ç‚¹å‡»ä¸‹æ–¹ğŸ‘‡ç»„å›¢é›†å¡æŠ½çº¢åŒ…,çœåˆ°å°±æ˜¯èµšåˆ°': '',
    'ğŸ‘†å¦‚æœæ‚¨å¸Œæœ›å¯ä»¥æ—¶å¸¸è§é¢ï¼Œæ¬¢è¿æ ‡æ˜ŸğŸŒŸæ”¶è—å“¦~': '',
    'ğŸ‘†å¦‚æœæ‚¨å¸Œæœ›å¯ä»¥æ—¶å¸¸è§é¢,æ¬¢è¿æ ‡æ˜ŸğŸŒŸæ”¶è—å“¦~': '',
    'irm.cn': 'irm', 'eå…¬å¸è®¯,': '',
    'æ™ºé€šè´¢ç»APPè®¯,': '', 'æ™ºé€šè´¢ç»APPè·æ‚‰,': '', 'æ™ºä¸œè¥¿(å…¬ä¼—å·:zhidxcom)': '',
    'è¯åˆ¸ä¹‹æ˜Ÿæ¶ˆæ¯,': '', 'è¯åˆ¸æ—¶æŠ¥ç½‘è®¯,': '', 'è¯åˆ¸æ—¶æŠ¥ä¼æŸ¥æŸ¥APPæ˜¾ç¤º,è¿‘æ—¥,': '',
    'èµ„è®¯æ­£æ–‡/!normalize.cssv7.0.0|MITLicense|github.com/necolas/normalize.css/html(line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%)body(margin:0)article,aside,footer,header,nav,section(display:block)h1(font-size:2em;margin:.67em0)figcaption,figure,main(display:block)figure(margin:1em40px)hr(-webkit-box-sizing:content-box;box-sizing:content-box;height:0;overflow:visible)pre(font-family:monospace,monospace;font-size:1em)a(background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects)abbr(title)(border-bottom:none;text-decoration:underline;-webkit-text-decoration:underlinedotted;text-decoration:underlinedotted)b,strong(font-weight:inherit;font-weight:bolder)code,kbd,samp(font-family:monospace,monospace;font-size:1em)dfn(font-style:italic)mark(background-color:ff0;color:000)small(font-size:80%)sub,sup(font-size:75%;line-height:0;position:relative;vertical-align:baseline)sub(bottom:-.25em)sup(top:-.5em)audio,video(display:inline-block)audio:not((controls))(display:none;height:0)img(border-style:none)svg:not(:root)(overflow:hidden)button,input,optgroup,select,textarea(font-family:sans-serif;font-size:100%;line-height:1.15;margin:0)button,input(overflow:visible)button,select(text-transform:none)(type=reset),(type=submit),button,html(type=button)(-webkit-appearance:button)(type=button)::-moz-focus-inner,(type=reset)::-moz-focus-inner,(type=submit)::-moz-focus-inner,button::-moz-focus-inner(border-style:none;padding:0)(type=button):-moz-focusring,(type=reset):-moz-focusring,(type=submit):-moz-focusring,button:-moz-focusring(outline:1pxdottedButtonText)fieldset(padding:.35em.75em.625em)legend(-webkit-box-sizing:border-box;box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal)progress(display:inline-block;vertical-align:baseline)textarea(overflow:auto)(type=checkbox),(type=radio)(-webkit-box-sizing:border-box;box-sizing:border-box;padding:0)(type=number)::-webkit-inner-spin-button,(type=number)::-webkit-outer-spin-button(height:auto)(type=search)(-webkit-appearance:textfield;outline-offset:-2px)(type=search)::-webkit-search-cancel-button,(type=search)::-webkit-search-decoration(-webkit-appearance:none)::-webkit-file-upload-button(-webkit-appearance:button;font:inherit)details,menu(display:block)summary(display:list-item)canvas(display:inline-block)template(display:none)(hidden)(display:none):root(font-size:50px)ul(padding:0;margin:0)ulli(list-style:none)ai-news-detail(color:333;font-family:PingFangSCRegular,PingFangSC-Regular,microsoftyahei,"\5B8B\4F53",tahoma,arial,simsun,sans-serif;padding:.32rem.32rem.48rem)ai-news-detail)p(font-size:.32rem;line-height:.44rem;margin:00.58rem)ai-news-detail.change-list)li(margin:00.52rem)ai-news-detail.change-list)lih2(font-size:.3rem;line-height:.42rem;margin:00.38rem;font-family:PingFangSC-Medium,PingFangSC-Regular,PingFangSCRegular,microsoftyahei,"\5B8B\4F53",tahoma,arial,simsun,sans-serif)ai-news-detail.change-list)li)ul(display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex)ai-news-detail.change-list)li)ulli(-webkit-box-flex:1;-webkit-flex:1;-ms-flex:1;flex:1;padding:000.37rem)ai-news-detail.change-list)li)ulli:first-of-type(padding:0.37rem00;position:relative)ai-news-detail.change-list)li)ulli:first-of-type:after(content:"";position:absolute;top:50%;right:0;height:80%;width:1px;background:dfdfdf;-webkit-transform:scaleX(.5)translateY(-50%);-ms-transform:scaleX(.5)translateY(-50%);transform:scaleX(.5)translateY(-50%))ai-news-detail.change-list)li)ullih3(color:999;font-size:.26rem;line-height:.36rem;margin:00.16rem)ai-news-detail.change-list)li)ulli.compare-itemp(margin:0;line-height:.46rem;font-size:.28rem)': '',
    'èµ„è®¯æ­£æ–‡     /*! normalize.css v7.0.0 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figcaption,figure,main{display:block}figure{margin:1em 40px}hr{-webkit-box-sizing:content-box;box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}dfn{font-style:italic}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:sans-serif;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{-webkit-box-sizing:border-box;box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{display:inline-block;vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{-webkit-box-sizing:border-box;box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details,menu{display:block}summary{display:list-item}canvas{display:inline-block}template{display:none}[hidden]{display:none}:root{font-size:50px}ul{padding:0;margin:0}ul li{list-style:none}#ai-news-detail{color:#333;font-family:PingFang SC Regular,PingFangSC-Regular,microsoft yahei,"\5B8B\4F53",tahoma,arial,simsun,sans-serif;padding:.32rem .32rem .48rem}#ai-news-detail>p{font-size:.32rem;line-height:.44rem;margin:0 0 .58rem}#ai-news-detail .change-list>li{margin:0 0 .52rem}#ai-news-detail .change-list>li h2{font-size:.3rem;line-height:.42rem;margin:0 0 .38rem;font-family:PingFangSC-Medium,PingFangSC-Regular,PingFang SC Regular,microsoft yahei,"\5B8B\4F53",tahoma,arial,simsun,sans-serif}#ai-news-detail .change-list>li>ul{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex}#ai-news-detail .change-list>li>ul li{-webkit-box-flex:1;-webkit-flex:1;-ms-flex:1;flex:1;padding:0 0 0 .37rem}#ai-news-detail .change-list>li>ul li:first-of-type{padding:0 .37rem 0 0;position:relative}#ai-news-detail .change-list>li>ul li:first-of-type:after{content:"";position:absolute;top:50%;right:0;height:80%;width:1px;background:#dfdfdf;-webkit-transform:scaleX(.5) translateY(-50%);-ms-transform:scaleX(.5) translateY(-50%);transform:scaleX(.5) translateY(-50%)}#ai-news-detail .change-list>li>ul li h3{color:#999;font-size:.26rem;line-height:.36rem;margin:0 0 .16rem}#ai-news-detail .change-list>li>ul li .compare-item p{margin:0;line-height:.46rem;font-size:.28rem} ': '',
    'è½¬è‡ª:ä¸Šæµ·è¯åˆ¸æŠ¥ä¸­å›½è¯åˆ¸ç½‘ä¸Šè¯æŠ¥ä¸­å›½è¯åˆ¸ç½‘è®¯': '', 'è½¬è‡ª:ä¸Šæµ·è¯åˆ¸æŠ¥': '', 'è½¬è‡ª:å•†åŠ¡å¾®æ–°é—»': '',
    'è½¬è‡ª:å±±è¥¿å‘å¸ƒ': '', 'è½¬è‡ª:äººæ°‘æ—¥æŠ¥æµ·å¤–ç‰ˆ': '', 'è½¬è‡ª:äººæ°‘æ—¥æŠ¥': '', 'è½¬è‡ª:äººæ°‘æ”¿åç½‘': '', 'è½¬è‡ª:äººæ°‘æ”¿åæŠ¥': '',
    'è½¬è‡ª:ä¸Šæµ·è¯åˆ¸æŠ¥ä¸­å›½è¯åˆ¸ç½‘è®¯': '', 'è½¬è‡ª:ä¸Šè§‚æ–°é—»': '', 'è½¬è‡ª:ä¸Šæµ·å¸‚åŸºé‡‘åŒä¸šå…¬ä¼š': '', 'è½¬è‡ª:äººæ°‘è®ºå›': '',
    'è½¬è‡ª:è¡¢å·æ—¥æŠ¥': '', 'è½¬è‡ª:é’è•‰è§†é¢‘': '', 'è½¬è‡ª:ç§¦çš‡å²›æ–°é—»ç½‘': '', 'è½¬è‡ª:åƒé¾™ç½‘ä¸­æ–°ç½‘': '', 'è½¬è‡ª:åƒé¾™ç½‘': '',
    'è½¬è‡ª:èµ·ç‚¹æ–°é—»': '', 'è½¬è‡ª:é½é²æ™šæŠ¥': '', 'è½¬è‡ª:é½é²å£¹ç‚¹': '', 'è½¬è‡ª:é½é²ç½‘': '', 'è½¬è‡ª:å‰ç»ç½‘': '',
    'è½¬è‡ª:ä¸­å›½æ–°é—»ç½‘': '', 'è½¬è‡ª:ä¸­å›½ç½‘': '', 'è½¬è‡ª:æœŸè´§æ—¥æŠ¥': '', 'è½¬è‡ª:å†œæ°‘æ—¥æŠ¥': '', 'è½¬è‡ª:å†…è’™å¤æ—¥æŠ¥': '',
    'è½¬è‡ª:å—äº¬æ™¨æŠ¥': '', 'è½¬è‡ª:å—æ¹–æ™šæŠ¥': '', 'è½¬è‡ª:å—æ–¹æ—¥æŠ¥': '', 'è½¬è‡ª:è¾½å®æ—¥æŠ¥': '', 'è½¬è‡ª:ä¹æ´¾æ–°é—»': '',
    '????': '', '???': ''
}
if PHRASE_MAP:
    # æ„é€ ä¸€æ¬¡æ€§æ­£åˆ™ï¼ˆæŒ‰é•¿åº¦é™åºï¼Œé¿å…å­ä¸²å¹²æ‰°ï¼‰
    _phr_keys = sorted(PHRASE_MAP.keys(), key=len, reverse=True)
    RE_PHRASES = re.compile('|'.join(map(re.escape, _phr_keys)))
else:
    RE_PHRASES = None


# ---------- åŸºç¡€å·¥å…· ----------

def _normalize_series(s: pd.Series) -> pd.Series:
    """å‘é‡åŒ–è§„èŒƒåŒ–ï¼šç»Ÿä¸€ç©ºç™½/æ ‡ç‚¹ï¼Œç§»é™¤å¸¸è§å™ªå£°æ¨¡æ¿ã€‚"""
    s = s.fillna('')
    s = s.str.replace(RE_SPACES, '', regex=True)
    s = s.str.replace(RE_HTML_ENT, '', regex=True)
    s = s.str.translate(TRANS_TABLE)
    if RE_PHRASES is not None:
        s = s.str.replace(RE_PHRASES, lambda m: PHRASE_MAP.get(m.group(0), ''), regex=True)
    s = s.str.replace(RE_DOLLAR_NONNUM, '', regex=True)
    s = s.str.replace(RE_PAREN_NOISE, '', regex=True)
    s = s.str.replace(RE_BAODAO, '', regex=True)
    s = s.str.replace(RE_TYC, '', regex=True)
    s = s.str.replace(RE_IT_HOUSE, '', regex=True)
    s = s.str.replace(RE_MULTI_DOTS, '.', regex=True)
    return s


def preprocess_dataframe(df: pd.DataFrame,
                         drop_dup_title: bool = False,
                         drop_dup_text: bool = False,
                         keep_original: bool = True) -> pd.DataFrame:
    """
    å¯¹è¾“å…¥çš„ DataFrame è¿›è¡Œæ–‡æœ¬é¢„å¤„ç†ï¼Œè¦æ±‚è‡³å°‘åŒ…å« ['title', 'text'] åˆ—ã€‚

    é¢„å¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š
    - ä¸¥æ ¼å»é™¤ç©ºå€¼ï¼ˆå°†ç©ºå­—ç¬¦ä¸²è§†ä½œ NaNï¼‰ï¼›
    - å¯¹ title å’Œ text å­—æ®µè¿›è¡Œè§„èŒƒåŒ–å¤„ç†ï¼Œç”Ÿæˆ title_norm å’Œ text_normï¼›
    - åˆæˆ doc_norm å­—æ®µï¼štitle_norm + 'ã€‚' + text_normï¼›
    - å¯é€‰åœ°æ ¹æ® title_norm æˆ– text_norm å»é™¤é‡å¤è¡Œï¼›
    - è¿”å›é¢„å¤„ç†åçš„ DataFrameï¼Œä¸è¿›è¡Œèšç±»ç­‰åç»­å¤„ç†ã€‚

    å‚æ•°ï¼š
        df (pd.DataFrame): è¾“å…¥çš„ DataFrameï¼Œå¿…é¡»åŒ…å« 'title' å’Œ 'text' åˆ—ã€‚
        drop_dup_title (bool): æ˜¯å¦æ ¹æ® title_norm å»é‡ï¼Œé»˜è®¤ä¸º Falseã€‚
        drop_dup_text (bool): æ˜¯å¦æ ¹æ® text_norm å»é‡ï¼Œé»˜è®¤ä¸º Falseã€‚
        keep_original (bool): æ˜¯å¦ä¿ç•™åŸå§‹çš„ title å’Œ text åˆ—ï¼Œé»˜è®¤ä¸º Trueã€‚

    è¿”å›ï¼š
        pd.DataFrame: é¢„å¤„ç†åçš„ DataFrameï¼ŒåŒ…å« title_normã€text_norm å’Œ doc_norm åˆ—ï¼Œ
                      è‹¥ keep_original ä¸º Trueï¼Œåˆ™è¿˜ä¿ç•™åŸå§‹çš„ title å’Œ text åˆ—ã€‚
    """
    if not {'title', 'text'}.issubset(df.columns):
        raise ValueError("è¾“å…¥ DataFrame å¿…é¡»åŒ…å«åˆ—ï¼š['title','text']")

    out_cols = ['title', 'text'] if keep_original else []
    # ä¸¥æ ¼å»ç©ºï¼ˆç©ºä¸²ç­‰ä»· NaNï¼‰
    df = df[['title', 'text']].copy()
    df['title'] = df['title'].replace('', np.nan)
    df['text'] = df['text'].replace('', np.nan)
    df = df.dropna(subset=['title', 'text']).reset_index(drop=True)

    # è§„èŒƒåŒ– title å’Œ text åˆ—ï¼Œç”Ÿæˆå¯¹åº”çš„ *_norm åˆ—
    title_norm = _normalize_series(df['title'])
    text_norm = _normalize_series(df['text'])

    # æ‹¼æ¥ title_norm å’Œ text_norm å¾—åˆ° doc_norm
    doc_norm = title_norm.str.cat(text_norm, sep='ã€‚', na_rep='').str.strip()

    # ç»„è£…è¾“å‡º DataFrame
    res = pd.DataFrame({
        **({'title': df['title']} if keep_original else {}),
        **({'text': df['text']} if keep_original else {}),
        'title_norm': title_norm,
        'text_norm': text_norm,
        'doc_norm': doc_norm
    })

    # åˆ é™¤ doc_norm ä¸ºç©ºçš„è¡Œ
    res = res[res['doc_norm'].str.len() > 0].reset_index(drop=True)

    # å¯é€‰ï¼šæŒ‰è§„èŒƒåŒ–åçš„ title æˆ– text å»é‡
    if drop_dup_title:
        res = res.loc[~res['title_norm'].duplicated()].reset_index(drop=True)
    if drop_dup_text:
        res = res.loc[~res['text_norm'].duplicated()].reset_index(drop=True)

    return res


# ---------- IO ----------

def read_any(input_path: str) -> pd.DataFrame:
    """æ ¹æ®æ‰©å±•åè‡ªåŠ¨è¯»å– parquet/csv/json/jsonlã€‚"""
    ext = os.path.splitext(input_path)[1].lower()
    if ext in ('.parquet', '.pq'):
        return pd.read_parquet(input_path)
    if ext in ('.csv',):
        return pd.read_csv(input_path)
    if ext in ('.jsonl', '.jsonl.gz'):
        return pd.read_json(input_path, lines=True)
    if ext in ('.json',):
        return pd.read_json(input_path)
    # é»˜è®¤å°è¯• parquetï¼Œå†é€€å› csv
    try:
        return pd.read_parquet(input_path)
    except Exception:
        return pd.read_csv(input_path)


def write_outputs(df: pd.DataFrame,
                  out_parquet: Optional[str],
                  out_excel: Optional[str]) -> None:
    if out_parquet:
        df.to_parquet(out_parquet, index=False)
        print(f"[INFO] ä¿å­˜åˆ° {out_parquet} å®Œæˆ")
    if out_excel:
        df.to_excel(out_excel, index=False)
        print(f"[INFO] ä¿å­˜åˆ° {out_excel} å®Œæˆ")


def main(drop_dup_title=True, drop_dup_text=True, keep_original=True,
         input_pq='test_news.parquet', out_pq='test_news_clean.parquet', out_excel='test_news_clean.xlsx'):
    print(f"[INFO] è¯»å–ï¼š{input_pq}")
    df = read_any(input_pq)

    # éªŒè¯è¾“å…¥æ•°æ®æ˜¯å¦åŒ…å«å¿…éœ€çš„åˆ—ï¼Œå¹¶å°è¯•è‡ªåŠ¨é€‚é…å¤§å°å†™ä¸åŒçš„åˆ—å
    if not {'title', 'text'}.issubset(df.columns):
        # å…è®¸ä¸åŒå¤§å°å†™/è¯­è¨€ç¯å¢ƒçš„åˆ—åï¼Œå°è¯•è‡ªåŠ¨é€‚é…
        lower_map = {c.lower(): c for c in df.columns}
        if 'title' in lower_map and 'text' in lower_map:
            df = df.rename(columns={lower_map['title']: 'title', lower_map['text']: 'text'})
        else:
            raise ValueError("è¾“å…¥æ•°æ®å¿…é¡»åŒ…å«åˆ— 'title' ä¸ 'text'ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ã€‚")

    print(f"[INFO] åŸå§‹æ¡æ•°ï¼š{len(df)}")

    # æ‰§è¡Œæ•°æ®é¢„å¤„ç†ï¼ŒåŒ…æ‹¬å»é‡ç­‰æ“ä½œ
    res = preprocess_dataframe(
        df,
        drop_dup_title=drop_dup_title,
        drop_dup_text=drop_dup_text,
        keep_original=keep_original  # é»˜è®¤ä¿ç•™åŸå§‹åˆ—ï¼Œä¾¿äºå®¡è®¡
    )

    print(f"[INFO] é¢„å¤„ç†å®Œæˆï¼Œå‰©ä½™æ¡æ•°ï¼š{len(res)}")

    # â€”â€” åœ¨é¢„å¤„ç†ç»“æœä¸Šæå–â€œé‡‘èç•Œå‡€å€¼ç±»å¿«è®¯â€å¹¶å•ç‹¬å¯¼å‡º â€”â€”
    jrj_df = extract_jrj_nav_rows(res)
    if not jrj_df.empty:
        jrj_excel = "jrj_news_clean.xlsx"
        jrj_parquet = "jrj_news_clean.parquet"
        jrj_df.to_excel(jrj_excel, index=False)
        jrj_df.to_parquet(jrj_parquet, index=False)
        print(f"[INFO] é‡‘èç•Œå‡€å€¼ç±»æ–°é—»åŒ¹é… {len(jrj_df)} æ¡ï¼Œå·²å¦å­˜ä¸ºï¼š{jrj_excel} & {jrj_parquet}")
        print(f"[INFO] ä»åŸæ•°æ®ä¸­å‰”é™¤é‡‘èç•ŒåŸºé‡‘æ–°é—»")
        res = res[~res['doc_norm'].isin(jrj_df['doc_norm'])].reset_index(drop=True)
        print(f"[INFO] å‰©ä½™æ¡æ•°ï¼š{len(res)}")
    else:
        print("[INFO] æœªåŒ¹é…åˆ°é‡‘èç•Œå‡€å€¼ç±»æ–°é—»ã€‚")

    # â€”â€” æŠ½å–â€œæœ€æ–°æŠ«éœ²æ•°æ®æ˜¾ç¤ºâ€¦åå¤§é‡ä»“è‚¡â€å¹¶å•ç‹¬å¯¼å‡º â€”â€”
    top_df = extract_top_holdings_rows(res)
    if not top_df.empty:
        top_excel = "top_holdings_news_clean.xlsx"
        top_parquet = "top_holdings_news_clean.parquet"
        top_df.to_excel(top_excel, index=False)
        top_df.to_parquet(top_parquet, index=False)
        print(f"[INFO] é‡ä»“è‚¡å¿«è®¯åŒ¹é… {len(top_df)} æ¡ï¼Œå·²å¦å­˜ï¼š{top_excel} & {top_parquet}")
        print(f"[INFO] ä»åŸæ•°æ®ä¸­å‰”é™¤é‡ä»“è‚¡å¿«è®¯")
        res = res[~res['doc_norm'].isin(top_df['doc_norm'])].reset_index(drop=True)
        print(f"[INFO] å‰©ä½™æ¡æ•°ï¼š{len(res)}")
    else:
        print("[INFO] æœªåŒ¹é…åˆ°é‡ä»“è‚¡å¿«è®¯ã€‚")

    # â€”â€” æŠ½å–â€œè¯åˆ¸ä¹‹æ˜Ÿç›˜ä¸­æ¶ˆæ¯â€å¹¶å•ç‹¬å¯¼å‡º â€”â€”
    szx_df = extract_szx_intraday_rows(res)
    if not szx_df.empty:
        szx_excel = "szx_intraday_news_clean.xlsx"
        szx_parquet = "szx_intraday_news_clean.parquet"
        szx_df.to_excel(szx_excel, index=False)
        szx_df.to_parquet(szx_parquet, index=False)
        print(f"[INFO] è¯åˆ¸ä¹‹æ˜Ÿç›˜ä¸­æ¶ˆæ¯åŒ¹é… {len(szx_df)} æ¡ï¼Œå·²å¦å­˜ï¼š{szx_excel} & {szx_parquet}")
        print(f"[INFO] ä»åŸæ•°æ®ä¸­å‰”é™¤è¯åˆ¸ä¹‹æ˜Ÿç›˜ä¸­æ¶ˆæ¯")
        res = res[~res['doc_norm'].isin(szx_df['doc_norm'])].reset_index(drop=True)
        print(f"[INFO] å‰©ä½™æ¡æ•°ï¼š{len(res)}")
    else:
        print("[INFO] æœªåŒ¹é…åˆ°è¯åˆ¸ä¹‹æ˜Ÿç›˜ä¸­æ¶ˆæ¯ã€‚")

    # â€”â€” æŠ½å–â€œæœºæ„è¯„çº§å˜åŠ¨â€å¹¶å•ç‹¬å¯¼å‡º â€”â€”
    rate_df = extract_rating_change_rows(res)
    if not rate_df.empty:
        rate_excel = "rating_change_news_clean.xlsx"
        rate_parquet = "rating_change_news_clean.parquet"
        rate_df.to_excel(rate_excel, index=False)
        rate_df.to_parquet(rate_parquet, index=False)
        print(f"[INFO] æœºæ„è¯„çº§å¿«è®¯åŒ¹é… {len(rate_df)} æ¡ï¼Œå·²å¦å­˜ï¼š{rate_excel} & {rate_parquet}")
        print(f"[INFO] ä»åŸæ•°æ®ä¸­å‰”é™¤æœºæ„è¯„çº§å¿«è®¯")
        res = res[~res['doc_norm'].isin(rate_df['doc_norm'])].reset_index(drop=True)
        print(f"[INFO] å‰©ä½™æ¡æ•°ï¼š{len(res)}")
    else:
        print("[INFO] æœªåŒ¹é…åˆ°æœºæ„è¯„çº§å¿«è®¯ã€‚")

    # â€”â€” æŠ½å–â€œå·¥å•†ç™»è®°ä¿¡æ¯å‘ç”Ÿä»¥ä¸‹å˜åŠ¨â€æ•´æ®µå¹¶å•ç‹¬å¯¼å‡º â€”â€”
    biz_df = extract_bizreg_disclosure_rows(res)
    if not biz_df.empty:
        biz_excel = "bizreg_disclosure_news_clean.xlsx"
        biz_parquet = "bizreg_disclosure_news_clean.parquet"
        biz_df.to_excel(biz_excel, index=False)
        biz_df.to_parquet(biz_parquet, index=False)
        print(f"[INFO] å·¥å•†å˜æ›´æŠ«éœ²ç±»åŒ¹é… {len(biz_df)} æ¡ï¼Œå·²å¦å­˜ï¼š{biz_excel} & {biz_parquet}")
        print(f"[INFO] ä»åŸæ•°æ®ä¸­å‰”é™¤å·¥å•†å˜æ›´æŠ«éœ²ç±»")
        res = res[~res['doc_norm'].isin(biz_df['doc_norm'])].reset_index(drop=True)
        print(f"[INFO] å‰©ä½™æ¡æ•°ï¼š{len(res)}")
    else:
        print("[INFO] æœªåŒ¹é…åˆ°å·¥å•†å˜æ›´æŠ«éœ²ç±»æ­£æ–‡ã€‚")

    write_outputs(res, out_pq, out_excel)
    print(f"[INFO] å†™å‡ºå®Œæˆã€‚")


if __name__ == '__main__':
    ''' æœ€ç»ˆç»“æœæœ‰4åˆ—: title, text, title_norm, text_norm, doc_norm
    åˆ†åˆ«è¡¨ç¤º: æ ‡é¢˜, æ­£æ–‡, è§„èŒƒåŒ–æ ‡é¢˜, è§„èŒƒåŒ–æ­£æ–‡, åˆæˆçš„æ–‡æ¡£æ–‡æœ¬
    '''
    main(drop_dup_title=True, drop_dup_text=True, keep_original=True,
         input_pq='test_news.parquet',
         out_pq='test_news_clean.parquet', out_excel='test_news_clean.xlsx'
         )
