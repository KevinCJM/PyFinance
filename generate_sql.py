# rag_sql.py
import faiss, json, os, numpy as np
from sentence_transformers import SentenceTransformer
from openai import OpenAI  # ä¹Ÿå¯æ¢æˆ deepseek ç­‰
import os

os.environ["TOKENIZERS_PARALLELISM"] = "false"

CONFIG = {
    "json_path": "/Users/chenjunming/Desktop/KevinGit/PyFinance/table_definitions.json",
    "index_path": "/Users/chenjunming/Desktop/KevinGit/PyFinance/rag_index/faiss_index.bin",
    "mapping_path": "/Users/chenjunming/Desktop/KevinGit/PyFinance/rag_index/table_mapping.json",
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
    "top_k": 4,
    "openai_key": "sk-a221b0c62c8a460693fe00a627d4598e",
    "openai_base": "https://api.deepseek.com",  # å¦‚æœèµ° DeepSeek
    "llm_model": "deepseek-chat"  # GPT-4o / gpt-3.5-turbo äº¦å¯
}


def load_resources():
    index = faiss.read_index(CONFIG["index_path"])
    with open(CONFIG["mapping_path"], "r", encoding="utf-8") as f:
        table_names = json.load(f)
    embedder = SentenceTransformer(CONFIG["embedding_model"])
    return index, table_names, embedder


def search_tables(query, index, embedder, table_names, top_k=4):
    q_emb = embedder.encode([query])  # shape (1, dim)
    D, I = index.search(np.asarray(q_emb, dtype="float32"), top_k)
    hits = [(table_names[i], float(D[0][rank])) for rank, i in enumerate(I[0])]
    return hits  # è¿”å› (è¡¨å, è·ç¦») åˆ—è¡¨


def build_prompt(query, hits, table_definitions):
    context_blocks = []
    for tbl, _ in hits:
        info = table_definitions[tbl]
        # åªæ”¾å…³é”®ä¿¡æ¯ï¼Œé¿å… token è¿‡å¤§
        block = (
            f"è¡¨å: {tbl}ï¼ˆ{info['tableChiName']}ï¼‰\n"
            f"è¯´æ˜: {info['description']}\n"
            f"ä¸»é”®: {info['key']}\n"
            f"å­—æ®µ: {', '.join([c['åˆ—å'] for c in info['columns'][:15] if 'åˆ—å' in c])} ...\n"
        )
        context_blocks.append(block)
    context = "\n\n".join(context_blocks)

    prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±æ•°æ®å·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ•°æ®åº“å…ƒæ•°æ®ï¼Œä¸ºç”¨æˆ·ç¼–å†™é«˜è´¨é‡ SQLï¼š

### æ•°æ®åº“å…ƒæ•°æ®
{context}

### ç”¨æˆ·éœ€æ±‚
{query}

### è¦æ±‚
- SQL å¿…é¡»ä½¿ç”¨ ANSI SQL-92 è¯­æ³•ã€‚
- å¿…è¦æ—¶è¯·åˆç† JOINï¼ŒJOIN æ¡ä»¶ä¼˜å…ˆä½¿ç”¨ä¸»é”®/å¤–é”® InnerCode ç­‰ã€‚
- åªè¿”å› SQL ä»£ç ï¼Œä¸è¦é™„å¸¦è§£é‡Šã€‚
"""
    return prompt.strip()


def call_llm(prompt):
    client = OpenAI(api_key=CONFIG["openai_key"], base_url=CONFIG["openai_base"])
    resp = client.chat.completions.create(
        model=CONFIG["llm_model"],
        messages=[
            {"role": "system", "content": "You are a senior SQL expert."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )
    return resp.choices[0].message.content.strip()


def main(query=None):
    index, names, embedder = load_resources()
    with open(CONFIG["json_path"].replace("table_definitions", "table_definitions"), "r", encoding="utf-8") as f:
        table_defs = json.load(f)

    if query is None:
        query = input("è¯·è¾“å…¥ SQL æŸ¥è¯¢éœ€æ±‚: ")
    hits = search_tables(query, index, embedder, names, CONFIG["top_k"])
    print("ğŸ” Top-k æ£€ç´¢ç»“æœ:", hits)

    prompt = build_prompt(query, hits, table_defs)
    sql = call_llm(prompt)
    print("\n=== ç”Ÿæˆçš„ SQL ===\n", sql)


if __name__ == "__main__":
    main()
